import requests
import re
import json
import subprocess
import platform
import requests
import time

def detect_pii_with_ollama(text, model='llama3.2-bllossom-kor-3B'):
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì´ë¦„, ì „í™”ë²ˆí˜¸, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ì´ë©”ì¼, ì£¼ì†Œ ë“± **ê°œì¸ì •ë³´**ë¡œ íŒë‹¨ë˜ëŠ” í•­ëª©ë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.

ì¡°ê±´:
- ë‹¨ìˆœíˆ "ìˆë‹¤/ì—†ë‹¤"ê°€ ì•„ë‹ˆë¼, ì‹¤ì œ ë°œê²¬ëœ ê°œì¸ì •ë³´ ë¬¸ìì—´ì„ í•­ëª©ë³„ë¡œ ì •í™•íˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”.
- ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ê³ , ê²°ê³¼ë§Œ **JSON í˜•ì‹**ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
- ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ê³¼ ê°™ì€ JSONë§Œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ìˆœì„œì™€ í‚¤ ì´ë¦„ë„ ë™ì¼í•˜ê²Œ ìœ ì§€í•´ ì£¼ì„¸ìš”.

í˜•ì‹ ì˜ˆì‹œ:
{{
  "ì´ë¦„": ["í™ê¸¸ë™", "ê¹€ë¯¼ìˆ˜"],
  "ì „í™”ë²ˆí˜¸": ["010-1234-5678"],
  "ì´ë©”ì¼": ["test@example.com"],
  "ì£¼ì†Œ": ["ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123"],
  "ê¸°íƒ€": ["900101-1234567"]
}}

ì´ì œ ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”:
{text[:2000]}
"""


    try:
        response = requests.post(
            'http://localhost:11434/api/generate',
            json={'model': model, 'prompt': prompt, 'stream': False}
        )
        result = response.json()
        raw_output = result.get('response', '')

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_match = re.search(r'\{.*\}', raw_output, re.DOTALL)
        if not json_match:
            raise ValueError("JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

        json_str = json_match.group(0)
        pii_data = json.loads(json_str)
        return pii_data
    except Exception as e:
        print("[âš ï¸] LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", e)
        return {}


def ollamaRunningCheck():
    try:
        res = requests.get("http://localhost:11434")
        return res.status_code == 200
    except Exception:
        return False

def startOllama():
    system = platform.system()
    print(f"[ğŸ§ ] Ollama ì„œë²„ í™•ì¸ ì¤‘...")

    if ollamaRunningCheck():
        print("[âœ…] Ollamaê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        return

    try:
        if system == 'Windows':
            # ìœˆë„ìš°ëŠ” start ëª…ë ¹ì–´ë¥¼ ì´ìš©í•´ ë³„ë„ ì½˜ì†”ì—ì„œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            subprocess.Popen("start ollama serve", shell=True)
        elif system == 'Darwin':  # macOS
            subprocess.Popen(["ollama", "serve"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        elif system == 'Linux':  # Ubuntu í¬í•¨
            subprocess.Popen(["ollama", "serve"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        else:
            raise RuntimeError("ì§€ì›ë˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤.")
        print("[ğŸš€] Ollama ì„œë²„ ì‹œì‘ ì¤‘... ì ì‹œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.")
        time.sleep(3)
    except Exception as e:
        print(f"[âŒ] Ollama ì‹¤í–‰ ì‹¤íŒ¨: {e}")